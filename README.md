# KAIROS: Automated Second-Order Effect Prediction üöÄ

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-blue)](https://huggingface.co/SharathReddy/kairos-llama3-finetune)

**KAIROS is an end-to-end, serverless system that uses a fine-tuned Large Language Model to perform real-time causal analysis on financial news, automatically predicting the non-obvious, second-order effects of events.**

---

## üì∫ Live Demo

Experience the live system in action! The dashboard updates automatically with the latest analysis as the AI pipeline runs.

**‚û°Ô∏è [kairos-skr.web.app](https://kairos-skr.web.app/)**

<img width="1549" alt="KAIROS-flowchart" src="https://github.com/user-attachments/assets/004351ed-cd8d-448b-b679-d995ba34645a" />


---

## üéØ The Problem: Beyond the Obvious

In financial markets, the most valuable insights often lie beyond the immediate, first-order consequences of an event.

* **First-Order Effect (Obvious):** A central bank raises interest rates.
* **Second-Order Effect (Non-Obvious):** Tech companies reliant on cheap debt for growth may see their profitability and stock valuations decline.

While state-of-the-art LLMs can summarize news (a first-order task), they struggle to reliably predict these deeper, causal ripple effects. Furthermore, their conversational outputs are often unreliable for automated, machine-driven systems, which require perfectly structured data like JSON. This is the **"Reliability Gap"** KAIROS was built to solve.

## üí° The Solution: A Specialized AI Agent

KAIROS bridges the Reliability Gap by leveraging a smaller, open-source model (`meta-llama/Meta-Llama-3-8B-Instruct`) that has been **fine-tuned** for one specific task: analyzing a news article and outputting a structured JSON object containing a summary, the predicted second-order effect, and the affected sectors.

This specialization, achieved through a technique called **QLoRA**, transforms a general-purpose model into a highly reliable and efficient expert agent.

---

## üèóÔ∏è System Architecture

KAIROS is a fully automated, event-driven, and serverless pipeline built on a multi-cloud architecture. The entire system is designed to be scalable, resilient, and cost-effective, running entirely within the free tiers of Google Cloud and Hugging Face.

![KAIROS Architecture Diagram](https://placehold.co/900x400/1a1a1a/ffffff?text=System+Architecture+Flowchart)
*High-level view of the KAIROS data pipeline.*

The pipeline works as follows:

1.  **‚è∞ Schedule (Google Cloud Scheduler):** A cron job triggers the pipeline hourly.
2.  **üì∞ Ingest (Google Cloud Function):** A Python function fetches the top 5 financial news articles from the [NewsAPI](https://newsapi.org/) and saves them to Firestore.
3.  **üß† Orchestrate & Analyze (Google Cloud Run):** A service retrieves each new article and calls our custom AI model for analysis.
4.  **ü§ñ Infer (Hugging Face Spaces):** Our fine-tuned `kairos-llama3-finetune` model, hosted on a GPU-powered Hugging Face Space, receives the article text and returns a structured JSON analysis.
5.  **üíæ Store (Firebase Firestore):** The structured JSON output is saved in a separate collection in the NoSQL database.
6.  **üìä Present (Firebase Hosting):** A vanilla JS and Tailwind CSS frontend connects to Firestore and displays the analysis in real-time. The dashboard updates automatically as new data arrives.

---

## üß† The KAIROS Model

The core intelligence of the system is a fine-tuned Llama 3 8B model.

* **Base Model:** [`meta-llama/Meta-Llama-3-8B-Instruct`](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
* **Fine-Tuning Technique:** **QLoRA** (Quantized Low-Rank Adaptation) on a single T4 GPU.
* **Dataset:** A custom `KAIROS-SOE` dataset of 100 examples, generated by "distilling" the knowledge from a larger model (Gemini 1.5 Pro) into a structured format.
* **Resulting Model:** [`SharathReddy/kairos-llama3-finetune`](https://huggingface.co/SharathReddy/kairos-llama3-finetune)

This process created a lightweight (~50MB) adapter that makes the base model an expert at our specific task, without the need to retrain all 8 billion parameters.

### ‚ú® Key Results

The fine-tuned model was evaluated against a zero-shot Gemini 1.5 Pro baseline. The results prove the power of specialization:

| Metric | KAIROS (Fine-Tuned Llama 3) | Baseline (Zero-Shot Gemini 1.5 Pro) |
| :--- | :---: | :---: |
| **JSON Validity** | ‚úÖ **100%** | ‚ùå **0%** |
| **Semantic Similarity** | **0.90** | 0.82 |

Our KAIROS model achieved **100% reliability** in producing machine-readable JSON, while the much larger baseline model failed every time. This is the critical differentiator for real-world automated systems.

---

## üõ†Ô∏è Tech Stack

| Frontend | Backend & Orchestration | AI & Deployment |
| :--- | :--- | :--- |
| ![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E) | ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) | ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) |
| ![TailwindCSS](https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?style=for-the-badge&logo=tailwind-css&logoColor=white) | ![Google Cloud](https://img.shields.io/badge/Google%20Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white) | ![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?style=for-the-badge) |
| ![HTML5](https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white) | ![Firebase](https://img.shields.io/badge/firebase-%23039BE5.svg?style=for-the-badge&logo=firebase&logoColor=white) | ![Transformers](https://img.shields.io/badge/Transformers-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black) |
| ![CSS3](https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white) | ![Node.js](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white) | ![Gradio](https://img.shields.io/badge/Gradio-FF7C00?style=for-the-badge&logo=gradio&logoColor=white) |

---

## ‚öôÔ∏è Setup & Installation

To set up and run this project locally, follow these steps.

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/SharathReddy/KAIROS.git](https://github.com/SharathReddy/KAIROS.git)
    cd KAIROS
    ```

2.  **Set up Google Cloud & Firebase:**
    * Create a new project on the [Google Cloud Console](https://console.cloud.google.com/).
    * Set up a new Firebase project and create a Firestore database.
    * Enable Cloud Functions, Cloud Run, and Cloud Scheduler APIs.
    * Create service account credentials and download the JSON key.

3.  **Install dependencies:**
    * **Frontend:** Navigate to the `frontend` directory and run `npm install`.
    * **Backend:** Navigate to the `backend` directory and install Python dependencies using `pip install -r requirements.txt`.

4.  **Configure Environment Variables:**
    * Create a `.env` file in the backend directory.
    * Add your `NEWS_API_KEY` and the path to your Google Cloud service account key.

5.  **Deploy:**
    * Deploy the Cloud Functions and Cloud Run services using the `gcloud` CLI.
    * Deploy the frontend using the `firebase` CLI.

---

## üìú License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
